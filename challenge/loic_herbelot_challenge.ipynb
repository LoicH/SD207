{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Challenge SD207 - 2017\n",
    "\n",
    "Acoustic scene classification\n",
    "\n",
    "Lo√Øc Herbelot\n",
    "\n",
    "# Data processing before classification:\n",
    "\n",
    "We take the samples, we extract the MFCC feature of these files to represent audio files with vectors (matrix in fact). We will then do the classifying on these data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: \n",
      "                   filename  label\n",
      "0     audio/b010_0_30.wav  beach\n",
      "1    audio/b010_60_90.wav  beach\n",
      "2  audio/b010_150_180.wav  beach\n",
      "3    audio/b010_30_60.wav  beach\n",
      "4  audio/b010_120_150.wav  beach\n",
      "5  audio/b022_120_150.wav  beach\n",
      "6    audio/b022_60_90.wav  beach\n",
      "7  audio/b022_180_210.wav  beach\n",
      "8    audio/b022_30_60.wav  beach\n",
      "9   audio/b022_90_120.wav  beach\n",
      "...\n",
      "(582 samples)\n",
      "\n",
      "Testing set:\n",
      "                  filename  label\n",
      "0    audio/b021_30_60.wav  beach\n",
      "1  audio/b021_150_180.wav  beach\n",
      "2   audio/b021_90_120.wav  beach\n",
      "3  audio/b021_120_150.wav  beach\n",
      "4    audio/b021_60_90.wav  beach\n",
      "5  audio/b021_180_210.wav  beach\n",
      "6     audio/b021_0_30.wav  beach\n",
      "7  audio/b019_180_210.wav  beach\n",
      "8  audio/b019_120_150.wav  beach\n",
      "9   audio/b019_90_120.wav  beach\n",
      "...\n",
      "(290 samples)\n",
      "\n",
      "Unknown set: \n",
      "                   filename\n",
      "0     audio/b053_0_30.wav\n",
      "1   audio/b035_90_120.wav\n",
      "2  audio/b089_210_240.wav\n",
      "3    audio/a034_30_60.wav\n",
      "4  audio/a045_150_180.wav\n",
      "5   audio/a058_90_120.wav\n",
      "6    audio/b029_60_90.wav\n",
      "7    audio/a079_30_60.wav\n",
      "8  audio/b055_137_167.wav\n",
      "9  audio/b049_150_180.wav\n",
      "...\n",
      "(298 samples)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "\n",
    "# Constants:\n",
    "data_home = \".\" #\"/tsi/plato/sons/sd207\"\n",
    "training_file = 'audio/train.txt'\n",
    "valid_file = 'audio/dev.txt'\n",
    "n_vectors = 72 # Each audio file will be represented by [n_vectors] vectors. Must be 1 < n_vectors < 1296.\n",
    "              # If possible, try to set n_vectors a divisor of 1296:\n",
    "              # 1, 2, 3, 4, 6, 8, 9, 12, 16, 18, 24, 27, 36, 48, 54, 72, 81, 108, 144, 162, 216, 324, 432, 648\n",
    "n_coefs = 60 # We will keep [n_coefs] MFC coefficients.\n",
    "\n",
    "labels_numbers = {\"beach\": 0,\n",
    "\"bus\": 1,\n",
    "\"cafe/restaurant\": 2,\n",
    "\"car\": 3,\n",
    "\"city_center\": 4,\n",
    "\"forest_path\": 5,\n",
    "\"grocery_store\": 6,\n",
    "\"home\": 7,\n",
    "\"library\": 8,\n",
    "\"metro_station\": 9,\n",
    "\"office\": 10,\n",
    "\"park\": 11,\n",
    "\"residential_area\": 12,\n",
    "\"train\": 13,\n",
    "\"tram\": 14}\n",
    "\n",
    "# Loading text files into pd.Dataframes\n",
    "training_set = pd.read_csv(data_home + '/' + training_file, sep='\\s+', \n",
    "                           dtype=str, names=['filename', 'label'])\n",
    "testing_set    = pd.read_csv(data_home + '/' + valid_file, sep='\\s+', \n",
    "                           dtype=str, names=['filename', 'label'])\n",
    "\n",
    "unknown_set    = pd.read_csv(data_home + '/test_files.txt', sep='\\s+', \n",
    "                           dtype=str, names=['filename'])\n",
    "\n",
    "print(\"Training set: \\n \", training_set[:10])\n",
    "print(\"...\\n(%d samples)\" % len(training_set))\n",
    "print(\"\\nTesting set:\\n\", testing_set[:10])\n",
    "print(\"...\\n(%d samples)\" % len(testing_set))\n",
    "print(\"\\nUnknown set: \\n \", unknown_set[:10])\n",
    "print(\"...\\n(%d samples)\" % len(unknown_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio files already processed, retrieving the file.\n",
      "You can check the shape of the data: (120, 41904)\n",
      "And labels: (41904,)\n",
      "Overview of labels:  ['beach' 'beach' 'beach' ..., 'tram' 'tram' 'tram']\n",
      "beach: 2736\n",
      "bus: 2808\n",
      "cafe/restaurant: 2736\n",
      "car: 2880\n",
      "city_center: 2880\n",
      "forest_path: 3024\n",
      "grocery_store: 2736\n",
      "home: 2880\n",
      "library: 2880\n",
      "metro_station: 2736\n",
      "office: 2664\n",
      "park: 2880\n",
      "residential_area: 2736\n",
      "train: 2592\n",
      "tram: 2736\n"
     ]
    }
   ],
   "source": [
    "# Load the audio files:\n",
    "\n",
    "def get_descr(path, n_coefs, n_vectors):\n",
    "    \"\"\"Returns a matrix description of an audio file.\n",
    "    \n",
    "    :param path: The path to the audio file\n",
    "    :param n_coefs: The numbers of MFC coefficients\n",
    "    :param n_vectors: number of vectors that will represent the audio file\n",
    "    \n",
    "    :return: ndarray of shape (2 * n_coefs, n_vectors) \n",
    "        where each column is the mean and standard deviation of MFCC sequence \n",
    "        of multiple frames in the audio file.\"\"\"\n",
    "    y, sr = librosa.load(path)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_coefs)\n",
    "    # We have too many columns in [mfcc], we will group them into [X]\n",
    "    X = np.zeros((2*n_coefs, n_vectors))\n",
    "    # Numbers of samples we will take to make one vector\n",
    "    p = mfcc.shape[1] // n_vectors \n",
    "    for i in range(n_vectors-1):\n",
    "        # We collapse the [p] vectors into one single column in [X]\n",
    "        X[:n_coefs,i]          = np.mean(mfcc[:,i*p:(i+1)*p], axis=1)\n",
    "        X[n_coefs:2*n_coefs,i] = np.std(mfcc[:,i*p:(i+1)*p], axis=1)\n",
    "    # Last vector:\n",
    "    i += 1\n",
    "    X[:n_coefs,i]          = np.mean(mfcc[:,i*p:], axis=1)\n",
    "    X[n_coefs:2*n_coefs,i] = np.std(mfcc[:,i*p:], axis=1)\n",
    "    return X\n",
    "\n",
    "def get_data_filename(descr, n_coefs, n_vectors):\n",
    "    \"\"\"Returns the file names used to save and load the data.\n",
    "    :param descr: The prefix of the files as a string\n",
    "    :param n_coefs: The number of MFC coefficients\n",
    "    :param n_vectors: The number of vectors that represent one audio file\n",
    "    \n",
    "    :return: set, label\n",
    "        set   - filename for the audio data\n",
    "        label - filename for the labels\"\"\"\n",
    "    return ('{0}_set_{1}coef_{2}vect.txt'.format(descr, n_coefs, n_vectors),\n",
    "            '{0}_labels_{1}coef_{2}vect.txt'.format(descr, n_coefs, n_vectors))\n",
    "\n",
    "def extract_features(dataframe, n_vectors, n_coefs, data_home=\".\",  saving='autosave', return_labels=True):\n",
    "    \"\"\" Extract the features from a batch of audio files and saves them in a file.\n",
    "    \n",
    "    :param dataframa:     pd.DataFrame, linking filename to labels. Must be the entire dataframe\n",
    "    :param data_home:     The path to the audio files\n",
    "    :param n_vectors:     The number of vectors that represent an audio sample\n",
    "    :param n_coefs:       The number of MFC coefficients to extract\n",
    "    :param saving:        The description of the filename saving the data.\n",
    "                          This function will save two files: the data from \n",
    "                          the audio files, and the labels.\n",
    "    :param return_labels: Wether or not to parse and return labels\n",
    "        \n",
    "    :return: data, labels\n",
    "        - data: ndarray of shape (n_coefs, N_samples * n_vectors) containing \n",
    "                the MFC coefficients for each audio samples\n",
    "        - labels: ndarray of shape (N_samples * n_vectors, ) containing the labels\n",
    "                for each vector. If 'return_labels' = True \"\"\"\n",
    "    filename_data, filename_labels = get_data_filename(saving, n_coefs, n_vectors)\n",
    "\n",
    "    if filename_data not in os.listdir() or (return_labels and filename_labels not in os.listdir()):\n",
    "        print(\"%s (or %s) not found in the folder.\" % (filename_data, filename_labels))\n",
    "        # Not already processed:\n",
    "        print(\"First time processing audio files.\")\n",
    "        n_samples = len(dataframe)\n",
    "        data = np.zeros((2*n_coefs, n_samples * n_vectors))\n",
    "        if return_labels:\n",
    "            labels = np.zeros(n_samples * n_vectors, dtype=object)\n",
    "        t0 = time.time()\n",
    "        # Get the description of all audio files:\n",
    "        for i, row in dataframe.iterrows():\n",
    "            if i%10==0:\n",
    "                print(\"Processed samples: %d/%d...\" % (i, n_samples))\n",
    "            descr = get_descr(data_home + '/' + row.filename, n_coefs, n_vectors)\n",
    "            data[:,i*n_vectors:(i+1)*n_vectors] = descr\n",
    "            if return_labels:\n",
    "                labels[i*n_vectors:(i+1)*n_vectors] = row.label\n",
    "        print(\"Done processing in %.2f\" % (time.time() - t0))\n",
    "        print(\"You can check the shape of the data:\",data.shape)\n",
    "        if return_labels:\n",
    "            print(\"And labels:\", labels.shape)\n",
    "        print(\"Saving the processed data.\")\n",
    "        np.savetxt(filename_data, data)\n",
    "        if return_labels:\n",
    "            np.savetxt(filename_labels, labels,  fmt=\"%s\")\n",
    "    else:\n",
    "        print(\"Audio files already processed, retrieving the file.\")\n",
    "        data = np.loadtxt(filename_data)\n",
    "        print(\"You can check the shape of the data:\",data.shape)\n",
    "        if return_labels:\n",
    "            labels = np.array(pd.read_csv(filename_labels, header=None)).ravel()\n",
    "            print(\"And labels:\", labels.shape)\n",
    "            print(\"Overview of labels: \",labels)\n",
    "\n",
    "    if return_labels:\n",
    "        return data, labels\n",
    "    else:\n",
    "        return data\n",
    "\n",
    "data, labels = extract_features(training_set, n_vectors, n_coefs, data_home=data_home, saving=\"training\")\n",
    "counts = np.unique(labels, return_counts=True)\n",
    "print(\"Distribution of training samples:\")\n",
    "for i in range(len(counts[0])):\n",
    "    print(\"%s: %d\" % (counts[0][i], counts[1][i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Let's do the actual training and prediction !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selection: 'lda'\n",
      "Fitting the GridSearch classifier:\n",
      "Fitting 3 folds for each of 21 candidates, totalling 63 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/loic/.local/lib/python3.5/site-packages/sklearn/lda.py:6: DeprecationWarning: lda.LDA has been moved to discriminant_analysis.LinearDiscriminantAnalysis in 0.17 and will be removed in 0.19\n",
      "  \"in 0.17 and will be removed in 0.19\", DeprecationWarning)\n",
      "/home/loic/.local/lib/python3.5/site-packages/sklearn/qda.py:6: DeprecationWarning: qda.QDA has been moved to discriminant_analysis.QuadraticDiscriminantAnalysis in 0.17 and will be removed in 0.19.\n",
      "  \"in 0.17 and will be removed in 0.19.\", DeprecationWarning)\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   16.4s\n",
      "[Parallel(n_jobs=-1)]: Done  63 out of  63 | elapsed:   23.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished in 24.41 s.\n",
      "Best parameters:  {'solver': 'svd', 'n_components': 1}\n",
      "\n",
      "Selection: 'qda'\n",
      "Fitting the GridSearch classifier:\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    6.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished in 7.62 s.\n",
      "Best parameters:  {}\n",
      "\n",
      "Selection: 'knn'\n",
      "Fitting the GridSearch classifier:\n",
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:  8.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished in 483.94 s.\n",
      "Best parameters:  {'algorithm': 'auto', 'n_neighbors': 1, 'weights': 'uniform'}\n",
      "\n",
      "Selection: 'logit'\n",
      "Fitting the GridSearch classifier:\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/loic/.local/lib/python3.5/site-packages/sklearn/linear_model/sag.py:286: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/loic/.local/lib/python3.5/site-packages/sklearn/linear_model/sag.py:286: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/loic/.local/lib/python3.5/site-packages/sklearn/linear_model/sag.py:286: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/loic/.local/lib/python3.5/site-packages/sklearn/linear_model/sag.py:286: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/loic/.local/lib/python3.5/site-packages/sklearn/linear_model/sag.py:286: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/loic/.local/lib/python3.5/site-packages/sklearn/linear_model/sag.py:286: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/loic/.local/lib/python3.5/site-packages/sklearn/utils/optimize.py:203: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "/home/loic/.local/lib/python3.5/site-packages/sklearn/linear_model/sag.py:286: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/loic/.local/lib/python3.5/site-packages/sklearn/linear_model/sag.py:286: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/loic/.local/lib/python3.5/site-packages/sklearn/linear_model/sag.py:286: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/loic/.local/lib/python3.5/site-packages/sklearn/utils/optimize.py:203: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "/home/loic/.local/lib/python3.5/site-packages/sklearn/utils/optimize.py:203: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "/home/loic/.local/lib/python3.5/site-packages/sklearn/linear_model/sag.py:286: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/loic/.local/lib/python3.5/site-packages/sklearn/linear_model/sag.py:286: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/loic/.local/lib/python3.5/site-packages/sklearn/linear_model/sag.py:286: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed: 55.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished in 3476.08 s.\n",
      "Best parameters:  {'penalty': 'l2', 'C': 0.01, 'solver': 'newton-cg'}\n",
      "\n",
      "Selection: 'svr'\n",
      "Fitting the GridSearch classifier:\n",
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n"
     ]
    }
   ],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.lda import LDA\n",
    "from sklearn.qda import QDA\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "def most_frequent(array):\n",
    "    \"\"\" Return the most frequent element in a list\"\"\"\n",
    "    unique, counts = np.unique(array, return_counts=True)\n",
    "    return unique[counts.argmax()]  \n",
    "\n",
    "X = data.T\n",
    "y = np.array([labels_numbers[name] for name in labels])\n",
    "\n",
    "permut = np.random.permutation(len(X))\n",
    "X = X[permut]\n",
    "y = y[permut]\n",
    "\n",
    "regressors = {'knn':{'clf': KNeighborsRegressor(),\n",
    "                     'params': {'n_neighbors': np.arange(1, 20, 10, dtype=int),\n",
    "                              'weights': ('uniform', 'distance',),\n",
    "                              'algorithm': ('auto', 'ball_tree', )}\n",
    "                    },\n",
    "              'svr':{'clf':SVR(),\n",
    "                     'params': {'C' : np.logspace(-1,0,3),\n",
    "                                'epsilon' : np.logspace(-2,0,3),\n",
    "                                'kernel' : ('rbf', )}# 'poly', 'rbf')}\n",
    "                    },\n",
    "              'logit':{'clf':LogisticRegression(),\n",
    "                     'params': {'C' : np.logspace(-2,1,4),\n",
    "                                'penalty' : ('l2',),\n",
    "                                'solver': ('newton-cg', 'lbfgs', 'liblinear', 'sag')\n",
    "                               }\n",
    "                    },\n",
    "              'lda':{'clf':LDA(),\n",
    "                     'params': {'solver' : ('svd', 'lsqr', 'eigen'),\n",
    "                                'n_components': np.arange(1, 15, 2),\n",
    "                               }\n",
    "                    },\n",
    "              'qda':{'clf':QDA(),\n",
    "                     'params': {\n",
    "                               }\n",
    "                    },\n",
    "              'random_forest':{'clf':RandomForestRegressor(),\n",
    "                     'params': {'n_estimators': np.arange(5, 50, 10),\n",
    "                                'max_features': ('auto', ),#'sqrt', 'log2', None),\n",
    "                                'max_depth': np.logspace(1, 1.6, 3, dtype=int),\n",
    "                                'bootstrap': (True, ),#False),\n",
    "                                \n",
    "                               }\n",
    "                    }\n",
    "}\n",
    "\n",
    "\n",
    "choices = ['lda', 'qda', 'knn', 'logit', 'svr', 'random_forest']\n",
    "# Selecting the best parameters for the estimators and saving them\n",
    "# into [estimators]\n",
    "estimators = []\n",
    "for shortname in choices:\n",
    "    print(\"\\nSelection: '%s'\" % shortname)\n",
    "    cv = GridSearchCV(regressors[shortname]['clf'], regressors[shortname]['params'], \n",
    "                      verbose=1, n_jobs=-1)\n",
    "    t0 = time.time()\n",
    "    print(\"Fitting the GridSearch classifier:\")\n",
    "    cv.fit(X, y=y)\n",
    "    print(\"Finished in %.2f s.\" % (time.time() - t0))\n",
    "    print(\"Best parameters: \",cv.best_params_)\n",
    "    estimators.append((shortname, cv.best_estimator_))\n",
    "    \n",
    "\n",
    "print(\"\\n\\nFitting the VotingClassifer\")\n",
    "voting_clf = VotingClassifier(estimators, n_jobs=-1).fit(X, y)\n",
    "# print(\"Getting the predictions for the training class\")\n",
    "# clf_labels = voting_clf.predict(X)\n",
    "\n",
    "# print(\"Getting the votes:\")\n",
    "# votes = get_votes(labels_permut, clf_labels)\n",
    "# print(votes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Checking our classifier on the testing dataset:\n",
    "\n",
    "# Retrieve data\n",
    "dev_data, dev_labels = extract_features(testing_set, n_vectors, n_coefs, data_home=data_home, saving=\"testing\")\n",
    "\n",
    "# Iterate over the audio files\n",
    "for i, row in testing_set.iterrows():\n",
    "    # Retrieve the description of this audio file\n",
    "    descr = dev_data[:, i*n_vectors:(i+1)*n_vectors]\n",
    "    predictions = voting_clf.predict(descr.T).round()\n",
    "    # Select the most frequent prediction\n",
    "    prediction = most_frequent(predictions)\n",
    "    # eye candy:\n",
    "    if prediction == row.label:\n",
    "        successes += 1\n",
    "        print('‚úì', end=' ')\n",
    "    else:\n",
    "        print('‚úó', end=' ')\n",
    "    print(\"Prediction: '%s', should be '%s'\" % (prediction, row.label), end=\"\")\n",
    "    print(\"\\tSo far, success rate: %d/%d (%.2f %%)\" % (successes, i+1, successes/(i+1) * 100))\n",
    "print(\"Done. Success rate: %d/%d (%.2f %%)\" % (successes, i+1, successes/(i+1) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Prediction of unknown data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "os.rename(\"prediction.txt\", \"old_prediction.txt\")\n",
    "    \n",
    "# Check if the 'unknown' features are already extracted in a file:\n",
    "unknown_data = extract_features(unknown_set, n_vectors, n_coefs, \n",
    "                                data_home=data_home, saving=\"unknown\", return_labels=False)\n",
    "\n",
    "# Iterate over the audio files\n",
    "for i, row in unknown_set.iterrows():\n",
    "    # Retrieve the description of this audio file\n",
    "    descr = unknown_data[:, i*n_vectors:(i+1)*n_vectors]\n",
    "    predictions = voting_clf.predict(descr.T).round()\n",
    "    # Select the most frequent prediction\n",
    "    prediction = most_frequent(predictions)\n",
    "    # Output to the file:\n",
    "    with open(\"prediction.txt\", \"a+\") as f:\n",
    "        f.write(str(labels_numbers[prediction]) + '\\n')\n",
    "    if i%10 == 0:\n",
    "        print(\"Predicted %d/%d (%.0f %%)\" % (i, len(unknown_set), i/len(unknown_set) * 100))\n",
    "print(\"Finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
